\documentclass[12pt,a4paper,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{pdfpages}

\usepackage[titletoc]{appendix}

\usepackage{listings}
\usepackage{color}

\usepackage{graphicx}
\graphicspath{ {./images/} }

\usepackage{cite}
\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

\title{Bachelor thesis}
\author{Tomáš Belluš}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolor}{rgb}{0.95,0.95,0.95}
 
\lstdefinestyle{codestyle}{
    commentstyle=\color{blue},
    keywordstyle=\color{black},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    showstringspaces=false,
    captionpos=b,
}
\lstset{style=codestyle}

\lstdefinestyle{appendix}{
    basicstyle=\small\ttfamily,
    showstringspaces=false,
    captionpos=b,
    numbers=left,
    stepnumber=1,
    numberstyle=\small,
    breaklines=true,
}

\include{preamble/preamble}

\begin{document}

%title page
\include{preamble/title}

%assignment
\thispagestyle{empty}

\includepdf[pages=-]{preamble/bp_zadanie.pdf}

\newpage{}\thispagestyle{empty}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage

%declaration
\include{preamble/declaration}

% annotation
\include{preamble/annotation}

% acknowledgements
\include{preamble/acknowledgements}

% table of contents
\begingroup
\color{black}
\tableofcontents
\endgroup

\chapter{Introduction}
    Ever since the first two network devices, whether in telecommunications or computer networking, exchanged data in some manner, we began to urge ourselves to send, receive and analyze data. Sending and receiving for communicating, and analyzing for understanding. Nowadays, these concepts are very actual in network security, network statistics and network devices such as routers, switches, firewalls, servers or any end-point devices. Applications require fast packet capture mechanisms for further processing, to keep up with the world's ever-increasing trend of transfer rates.\par
    The Internet Protocol version 4 (IPv4) address range is, for a long time now, not enough for all devices connected to the largest network - the Internet. It implies that it is directly proportional to data being transferred over the Internet. This raises the need for applications, products or complex infrastructure solutions for keeping up with today's technologies. \par
    With increasing network transfers, the number of network devices, new frameworks and transfer protocols, improved algorithms and overall network security comes to the threat of data theft, (distributed) denial of service attacks, compromised the system or network and many other. Therefore, real-time network traffic analysis is of utmost importance for national security authorities (mainly cybernetic security department), security or network companies and even end-point users. Network traffic analysis includes understanding and depicting various indications of either unlawful actions for security reasons or network transfers for statistical purposes. For both, it means monitoring the correct functionality of network at hand.\par
    Furthermore, each packet provides different decisive protocols that indicate information about the connection nodes and service used. A full understanding of the TCP/IP model and its layers is crucial for analyzing these services. Application, transport, network and link layer comprise the TCP/IP stack. The application layer is where applications exchange raw data, and the transport layer connects sockets for data transfer, network layer forwards packets to destination and link layer checks the credibility and handles the closest physical device connections over medium.\par
    What are existing solutions to packet capturing mechanisms with network traffic analysis? How can we utilize existing packet capture mechanisms, reuse captured data analysis and identifying trends, threats and possibly predict future traffic? With packet capture and data analysis come storage systems, which need to be examined and evaluated. What known databases provide fast search process for real-time network analysis and at the same time fast insertion rate, which would be sufficient for wire speed captures?\par
    This thesis aims to answer and evaluate these questions. Besides, considers frameworks, systems, and mechanisms explicitly for UNIX systems. Implement a system for packet capturing, store captured data to the chosen database and finally analyze it with a framework or tools. Create visualizations of how the network behaves, depict trends, make predictions of given characteristics and analyze network packets on different TCP/IP layers.\par
    Chapter \ref{analysis} analyzes packet capturing process, distinctions among various \hyperref[analysis:mechs]{mechanisms} in \hyperref[analysis:testing]{performance} and techniques, \hyperref[analysis:storage]{storage systems}, \hyperref[analysis:data]{data for analysis} and  \hyperref[analysis:solutions]{existing solutions}. Chapter \ref{solution} focuses on \hyperref[solution:spec]{system specifications}, \hyperref[solution:design]{system design} including the system architecture, database system configuration and network traffic collector. Chapter \ref{implementation} outlines the key parts of implementation and deployment of the whole system. Chapter \ref{tests} describes the final testing results.
\chapter{Analysis} \label{analysis}
    \section{Packet capture mechanisms} \label{analysis:mechs}
        The most critical part is real-time data capture in network traffic, meaning capturing network packets using a framework or interpreted language library. It is a dependent process of hardware components like Network Interface Controller (NIC), processor performance and its properties (e.g. the number of processor cores). The capture of every packet, which can be processed by arbitrary mechanism ordinarily takes place in the higher system layer - the userspace. More efficient mechanisms have access to data, which fall under the jurisdiction of the lower system layer - kernel space. Though, why is it more effective and efficient to access data in lower system layers? Kernel space is the operating system's (OS) core and an interface to hardware for the OS. More precisely, it is the access to shared kernel space, which altogether bypasses the additional copying and processing present with basic frameworks not utilizing efficient features.\par
        Received data on NIC is stored in NIC buffers. NIC registers keep track of whether the buffers are full and ready for reading or sending. This indication is handled by interrupts from the NIC to the OS. OS copies the buffer content to kernel space buffers (called \emph{m\_buffs} or \emph{sk\_buff}\footnote{These kernel buffers are expensive to create and vary in size. They are complex and include a large amount of metadata. \cite{video:netmap}}). These buffers are not accessible by processes but can be copied to userspace or the process accessible memory. This is a typical scenario - two copies and interrupts needed for a process to access received data on the NIC. Possible improvements are to use, as mentioned above, buffers shared between kernel and userspace, which eliminates one or more copies and interrupts from user to kernel space, leaving only one copy between NIC buffers and shared buffers. Another possibility is to have a NIC supporting multiple buffers, which split the load and each buffer is handled by different core simultaneously \cite{report:netmap}.\par
        A problem arises with the ability to capture all traffic on the wire with no increasing delay resulting in packet loss due to lack of buffer space. A solution may be a zero-copy mechanism which utilizes a NIC dependent direct NIC access (DNA) or a one-copy mechanism, which utilizes the shared buffers. This section analyzes packet capture mechanisms, with various efficiency improvements at high packet rates in network traffic.
        \subsection{Scapy and RSS} \label{analysis:mechs:scapy_rss}
            \emph{Scapy}\footnote{\url{https://scapy.net/}} for Python running on Linux systems operates in userspace with no access to shared memory. At its core, it utilizes the libpcap library, and it is mainly a packet crafting library, packet decoder and a network sniffing mechanism on given interface \cite{web:scapy}. Also, it features filtering, detecting request responses and supports multiple existing protocols from all layers \cite{docs:scapy}. Even though it has complex packet parsing, which makes it simple to extract any field, it is a huge bottleneck. It is present due to known Python complexity in lower layers of its implementation. While using scapy is a fast solution from the development point of view, the execution time is crucial here. Therefore its packet capturing performance is insufficient (see~\autoref{analysis:testing}).\par
            New resolution to the bottleneck may be applying improvements to data processing on NIC driver level. It would require enabling CPU to process incoming packets by dividing received data among multiple CPU cores. On Linux platforms it is referred to as \emph{Receive-Side Scaling} \texttt{(RSS)} and it "distributes network receive processing across several hardware-based receive queues" \cite{web:redhat:rss}. More precisely, each queue is handled by a single core independently and simultaneously. Unfortunately, this feature is dependent on the NIC driver.
        \subsection{Packet socket} \label{analysis:mechs:socket}
            Creating a file descriptor \emph{packet socket}\footnote{\url{http://man7.org/linux/man-pages/man7/packet.7.html}} provides receiving and sending packets at data link layer. It means that packets are captured before any processing in the Linux network stack as raw frames including all protocol headers \cite{man:packet}. A packet socket with raw network protocol access (raw socket) is opened by a system call (see~\autoref{lst:socket}), where the first argument must be \emph{AF\_PACKET}\footnote{AF\_PACKET is interchangeable with PF\_PACKET, and they stand for Address Family, and Protocol Family respectively specified the communication domain.\cite{man:socket}} \cite{man:socket}, which indicates the protocol family. The \emph{SOCK\_RAW} parameter identifies that it is a raw socket providing a whole encapsulated Ethernet frame. Macro parameter \emph{ETH\_P\_ALL} specifies the socket protocol, which is expected to receive so in this case we require all protocols to be passed to socket interface \cite{man:packet}.
            \begin{lstlisting}[language=C, style=appendix, caption=Raw socket system call., label=lst:socket]
int fd = socket(AF_PACKET, SOCK_RAW, htons(ETH_P_ALL));
            \end{lstlisting}
            \par
            All in all, the packet socket is the interface receiving raw frames, or packets in case of trimming out link layer header, directly from the NIC and efficiently bypassing the network stack processing. This is an advantage concerning performance because it produces only one copy of received data (from NIC driver to packet socket file descriptor) \cite{thesis:muni}\cite{web:raw_socket}. The shared memory between kernel and userspace is the packet socket file descriptor. In contrast with basic address family \emph{AF\_INET}, packet socket provides socket option for packet capture statistics (PACKET\_STATISTICS), which is crucial for performance testing. In comparison with scapy, it is the opposite in development and execution time point of view - it is presumably faster than scapy but more complex to implement.\par
            \begin{figure}[h]
                \centering
                \includegraphics[scale=0.4]{linux_net_capture_struct}
                \caption{UNIX packet capture architecture for Libpcap or packet socket.}
                \label{figure:libpcap:struct}
            \end{figure}
        \subsection{Libpcap} \label{analysis:mechs:libpcap}
            \emph{Libpcap}\footnote{\url{http://www.tcpdump.org/manpages/pcap.3pcap.html}} is an user space library designed mainly for capturing Ethernet frames. It is a cross platform library for UNIX systems not only for C/C++ programming (e.g \emph{tcpdump}\footnote{\url{http://www.tcpdump.org/manpages/tcpdump.1.html}} and \emph{wireshark}\footnote{\url{https://www.wireshark.org/}}), but for other more abstract languages (Python, C\#, Java, etc.) it exists in form of wrappers \cite{article:libpcap}. An user space library does not utilize kernel network stack, rather it reads raw Ethernet frames from opened socket queue in kernel space. Therefore, frame decapsulation is handled by libpcap and any protocol data, of parsed frame at hand, is accessed by libpcap's Application Programming Interface (API) (see~\autoref{figure:libpcap:struct}). Libpcap uses PF\_PACKET \cite{presentation:socket} \cite{report:libpcap} since version 0.6 release (year 2001) with kernel 2.2 support and later \cite{git:libpcap0.6:changes}.\par
            Moreover, as of libpcap release 0.9.5, this library supports capture statistics for protocol family PF\_PACKET by a \emph{getsockopt()} system call \cite{git:libpcap0.9:changes}. In reference to \hyperref[analysis:mechs:scapy_rss]{scapy} and \hyperref[analysis:mechs:socket]{packet socket}, libpcap provides more abstraction to implementations by wrapping socket operations to library functions and similar performance to packet socket.
        \subsection{PF\_RING} \label{analysis:mechs:pfring}
            Moving from userspace library to the kernel space modules and possible zero-copy mechanisms bring \emph{PF\_RING}\footnote{\url{https://www.ntop.org/products/packet-capture/pf_ring/}}. On socket layer it is a protocol family, replacing PF\_PACKET, but it requires loading a kernel module. On the application layer, PF\_RING has an API for accessing received packets. PF\_RING lacking additional enhancements and independent of NIC driver is referred to as PF\_RING Vanilla. As of performance, through Linux New API (NAPI)\footnote{NAPI is a performance increase for packet capturing at higher packet rates, by enabling packet polling, therefore decreasing number of interrupts which otherwise would overwhelm the CPU \cite{web:linux:napi}} the kernel module copies polled packets from the NIC to shared memory ring buffers accessible by user application (see~\autoref{figure:pfring:overview})\cite{web:pfring:vanilla}. This process bypasses Linux network stack and the standard NIC driver. On the other hand, the performance depends on multiple hardware-based queues (\hyperref[analysis:mechs:scapy_rss]{RSS}) in the form of shared memory ring buffers (see~\autoref{lst:rss}). Nevertheless, at least one shared memory ring buffer is created after loading the module to kernel. \cite{docs:pfring:vanilla}
            \begin{lstlisting}[language=bash, caption=Enabling RSS \cite{docs:pfring:rss}., label=lst:rss]
insmod driver_module.ko RSS=4,4
# enables 4 queues per interface (in this case two)
# the driver_module is the PF_RING enabled NIC driver
            \end{lstlisting}
            \par
            Worth mentioning is the PF\_RING\_ZC, which is a zero-copy alternative to PF\_RING Vanilla. It is strictly NIC driver dependent framework, which neglects NAPI, kernel modules and standard NIC driver to maximize efficiency by directly accessing NIC (DNA) (see~\autoref{figure:pfring:overview}). Inserting the correct PF\_RING-provided NIC driver enables an interface to be opened in zero-copy mode\footnote{Interface in the zero-copy mode has the "zc:" prefix (e.g. eth0 in zero-copy mode is accessed by zc:eth0) \cite{docs:pfring:zero}.}. Any application can access packets through its API on 1-10 Gbit links at wire speed \cite{docs:pfring:zero}, if the kernel is bypassed. Otherwise, the driver replaces the standard NIC driver and is faster compared to PF\_RING Vanilla \cite{web:pfring:zero}. Disadvantages are, that while accessing NIC in zero-copy mode, standard networking is on hold until the device at hand is closed \cite{web:pfring:zero} and due to bypassing kernel packet filtering is missing \cite{docs:pfring:zero}.\par
            Most valuable is the modified libpcap library\footnote{\url{https://github.com/ntop/PF_RING/tree/dev/userland/libpcap-1.8.1}} (pfring-libpcap) provided by the PF\_RING framework. Pfring-libpcap requires the PF\_RING module inserted and applications need to be recompiled with linking the new libpcap and specifically linking PF\_RING library (libpfring) \cite{docs:pfring:libpcap}. 
            \begin{figure}[h]
                \centering
                \includegraphics[scale=0.35]{overall_pf_ring}
                \caption{PF\_RING variants and architecture overview \cite{image:ntop}.}
                \label{figure:pfring:overview}
            \end{figure}
        \subsection{Netmap} \label{analysis:mechs:netmap}
            Last, but not least capture mechanism with an API is \emph{netmap}\footnote{\url{http://info.iet.unipi.it/~luigi/netmap/}}. The current paragraph is derived from a report on Luigi Rizzo's netmap \cite{report:netmap}. "It is a framework to reduce the cost of moving traffic between hardware and the host stack" \cite{report:netmap}. Netmap targets the processing bottleneck by utilizing, similarly as PF\_RING or packet socket, the shared memory consisting of netmap packet buffers and netmap rings (buffer descriptors). The netmap packet buffers are shared between NIC rings and netmap rings, meaning that application processes access the packets in cost of one copy. In addition, the buffers are circular (ring buffers) and are designed (see~\autoref{figure:netmap:rings}) to eliminate most of the processing time. Standard NIC uses ring buffers for received data, and the implementation of netmap rings is a replica of those buffers. The \emph{netmap\_if} is a descriptor table of netmap rings mainly used when multiple netmap rings are used for load balancing. In contrast with standard Linux packet capturing (I/O operations) process, where the buffers holding packets (\emph{sk\_buffs} or \emph{m\_buffs}) are allocated and deallocated throughout the capturing process, the netmap framework preallocates \emph{pkt\_bufs} (see~\autoref{figure:netmap:rings}) to bypass this time consuming operation.\par
            \begin{figure}
                \centering
                \includegraphics[scale=0.3]{netmap_rings}
                \caption{Netmap ring buffer design \cite{image:netmap}.}
                \label{figure:netmap:rings}
            \end{figure}
            Moreover, it requires a modified driver to be loaded to kernel, which provides maximum performance at wire rate if the netmap native API is used. Just as PF\_RING, netmap provides a netmap-based libpcap by creating a modified library, which maps libpcap standard calls to netmap calls \cite{report:netmap}. Even though, the netmap libpcap has weaker performance in comparison with its native API, it does show improvement to the libpcap library \cite{video:netmap}. For compatibility purposes, opposing to the native API the netmap libpcap may be the most efficient mechanism variant.
    \section{Performance testing} \label{analysis:testing}
        All of the above are potentially effective packet capture mechanisms, but only a few are efficient enough to produce expected results in a reasonable time. Performance testing of any mechanism means to simulate the expected network traffic environment and mark down elapsed time or other performance output based on a specific mechanism. Requirements for the efficient capturing mechanism are minimal or no packet drop rate combined with wire-rate capture, bypassing kernel processing and minimizing data copies. Packet drop rate is the ratio of dropped packets and total packets received by a NIC during a given period of time. At wire rate capture, packets are received with no delay. Bypassing kernel altogether (except for handling interrupts) and minimizing data copies results in performance increase and it is an essential mechanism feature. These are the three aspects for testing and comparing all \hyperref[analysis:mechs]{mechanisms} analyzed.\par
        This section focuses on the performance testing process and its results. Packet capture efficiency (drop rate) of received traffic and time elapsed is measured and evaluated. Brief focus on \hyperref[analysis:testing:auto]{testing automation}, followed by the \hyperref[analysis:testing:tests]{specific tests} of both mentioned aspects and finally providing test \hyperref[analysis:testing:results]{results}.
        \subsection{Automation} \label{analysis:testing:auto}
            A bash script is used for efficient performance testing (see Appendices~\ref{appendix:script:testing}) of both packet capture efficiency and elapsed time of captured traffic. For most mechanisms the implementation is straightforward, but running multiple executables (binary files) of single C program with various libpcap versions requires additional variables. It was the most crucial part of testing since only one libpcap library version can be installed on a system. Appending the \emph{/etc/ld.so.conf} with directory paths of other libpcap versions partially solved the problem. Although, only one other libpcap version can be added this way since the linker works in a "first match" sense. For example, the target library was pfring-libpcap, but it was linked to netmap libpcap (see~\autoref{lst:compilation:pcap}).
            \begin{lstlisting}[language=bash, caption=Contents of /etc/ld.so.conf.d/libpcaps.conf., label=lst:compilation:pcap]
# paths to multiple libpcap libraries
/home/tomas/libpcaps/netmap-libpcap/
/home/tomas/libpcaps/PF_RING/userland/libpcap-1.8.1/
            \end{lstlisting}
            \par
            The solution is to link the library directly with the program source file and on execution prefix the binary with overriding the LD\_LIBRARY\_PATH \cite{web:libraries:ldpath} environment variable (see Appendix~\ref{appendix:compilation:pcaps}). This variable may contain library paths to be searched before the library configuration file is used (\emph{/etc/ld.so.conf}). Setting the variable in line with execution makes it temporary, rather than sourcing it every other execution for different libpcap version. Using the \emph{ldd} command, which prints the shared object dependencies, validates this method a success.
        \subsection{Tests} \label{analysis:testing:tests}
            \begin{figure}[h]
                \centering
                \includegraphics[scale=0.5]{diagram}
                \caption{Diagram of testing scenario}
                \label{figure:testing:diagram}
            \end{figure}
            \begin{table}[h!]
            \centering
            \begin{tabular}{ |p{2.0cm}||p{3.0cm}|p{1.3cm}|p{1.2cm}|p{3.0cm}| }
                 \hline
                 Machine & CPU & RAM & NIC & OS \\
                 \hline
                 Laptop A & Intel i5-7300HQ, 2.50GHz x4 & 16 GB & Realtek 1Gb & Ubuntu 18 64bit \\
                 \hline
                 Laptop B & Intel i5-2430M, 2,40Ghz x2 & 6 GB & Realtek 1Gb & Kali Linux 64bit \\
                 \hline
            \end{tabular}
            \caption{Computer hardware specifications}
            \label{table:pc_specs}
            \end{table}    
            Testing the packet capture efficiency required a traffic generator to simulate a high frequency of packets. For this purpose, Kali Linux has a generator tool \emph{hping3}, which is capable of sending 179 000 packets per second (179 Kpps) on a Realtek\footnote{RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller} adapter. Even though, it is not a perfect real life traffic simulator it is sufficient enough to depict differences between some mechanisms. The testing environment consisted of two computers as shown in \autoref{figure:testing:diagram} with specifications in \autoref{table:pc_specs}. Drop rate is the best indicator of an efficient capture mechanism. Each test was constructed by the \emph{hping3} command generating raw IP packets with 120-byte payload at different frequencies (see Appendix~\ref{appendix:hping3}). Each mechanism was implemented as a simple C program or Python script and tested 5 times in 30 second time blocks. Refer to the Appendix \ref{appendix:script:testing} with bash script for testing packet capture efficiency.\par        
            In contrast, testing capture elapsed time proves the wire speed capture of a mechanism. Similarly, \emph{hping3} tool was used for generating traffic at maximum rate (179 Kpps) using flood mode (see Appendix~\ref{appendix:hping3}). Each mechanism was tested 5 times with various number of packets to be captured subsequently returning elapsed time. Refer to the Appendix \ref{appendix:script:testing} for bash script testing elapsed time.\par
            In addition to this specific performance testing, a more precise and valuable tests were performed as part of the IIT.SRC 2019 conference included in Appendix \ref{appendix:iitsrc:paper}.
        \subsection{Results} \label{analysis:testing:results}
            Additional results conducted as part of the IIT.SRC 2019 conference are included in Appendix \ref{appendix:iitsrc:paper}.
            \subsubsection*{Packet capture efficiency} \label{analysis:testing:results:capture}
                %\chapter{Packet capture graphs} \label{appendix:tests:graph:drops}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.5]{overall_drops_line-graph}
                    \caption{Packet capture performance and efficiency.}
                    \label{figure:tests:alldrops}
                \end{figure}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.5]{closeup_drops_line-graph}
                    \caption{Packet capture performance and efficiency. Number of packets captured in a second.}
                    \label{figure:tests:closedrops}
                \end{figure}                
                
                
                Results have proven that scapy is not effective at higher packet rates (see~\autoref{figure:tests:alldrops}), which is due to the Python complexity. It makes the drop rate increase rapidly until more packets are dropped than captured (see~\autoref{table:scapy:drop}). Therefore, scapy is insufficient for capturing real-time network traffic.
                \begin{table}[h]
                    \centering
                \begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}| }
                     \hline
                     \multicolumn{4}{|c|}{Elapsed time test} \\
                     \hline
                     Packet rate [pkts/s] & received & captured & dropped \\
                     \hline
                     20    & 600 & 591 & 9 \\
                     194    & 5 820 & 5 726 & 94 \\
                     2 010    & 60 300 & 59 413 & 887 \\
                     20 050    & 601 500 & 87 711 & 513 789 \\
                     179 000    & 5 370 000 & 88 012 & 5 281 988 \\
                     \hline
                \end{tabular}
                    \caption{Scapy measured drop rate.}
                    \label{table:scapy:drop}
                \end{table}
                \par
                Moreover, other mechanisms were efficient and captured all the traffic (no packets were dropped due to lack of buffer space). Referring to \autoref{figure:tests:closedrops}, packet socket is significantly faster at capturing packets at small rates because it captures packets in a flow (one by one), rather than in batches\footnote{Capturing packets in batches means to copy or access multiple packets within one interrupt or read.}. As the rate increases, all mechanisms have zero drop rate and captured all packets. Deciding for a mechanism accords for potential zero-copy feature (netmap and PF\_RING), since all are equally efficient. Even though netmap and PF\_RING could be compared as equally efficient, there are some major aspects analyzed in their respective sections, which breaks the tie.\par
                Concerning this test, netmap is the most suitable choice, because it provides minimum copies of data received, it has no dropped packets, and it is utilized in a modified netmap-based libpcap library, which makes the program compatible with other libpcap versions.
            \subsubsection*{Capture elapsed time} \label{analysis:testing:results:timed}
                Measuring the elapsed time of a set of operations comprises of marking the time before and after the execution of target commands. This would be reliable if the system's time would not change due to the Network Time Protocol (NTP) bad update or other unpredictable changes. An alternative is a monotonic clock, which goes forward independently of the system's time. For Python scripts monotonic clock is included in \emph{time} module and for C it is included in \emph{time} library by \emph{clock\_gettime()}\footnote{\url{https://linux.die.net/man/3/clock_gettime}} system call.\par
                %\chapter{Packet capture elapsed time} \label{appendix:tests:graph:timed}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.39]{overall_speed_line-graph}
                    \caption{Capture performance for testing elapsed time. Each vertical step is 5 seconds.}
                    \label{figure:tests:alltimed}
                \end{figure}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.39]{closeup_speed_line-graph}
                    \caption{Close up graph of capture performance for testing elapsed time and discarding scapy.}
                    \label{figure:tests:closetimed}
                \end{figure}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.4]{speed_bar-graph}
                    \caption{Best performance at million sent packets.}
                    \label{figure:tests:timed:best}
                \end{figure}
                As it was for testing packet capture efficiency, the elapsed time of packet capture with scapy was radically slow. As a result, scapy was not tested for the maximum of million packets because of the predicted exponential increase (see~\autoref{figure:tests:alltimed}). In comparison, scapy was processing more than 30 seconds, while other mechanisms processed the same load in 500 ms. All other mechanisms captured packets in wire speed. \autoref{figure:tests:timed:best} compares average elapsed time for all considered mechanisms, and netmap has processed a million packets the shortest time. Even though, the bar graph shows differences between packet socket, netmap, PF\_RING and libpcap, their performance could be the same due to inconsistent packet rate on the wire. Nevertheless, netmap did not fail this performance test, so it remains as the most efficient choice.
                
        \subsection{Summary} \label{analysis:mechs:final}
            There are multiple mechanisms considered and analyzed, but finally, netmap remained as the most efficient choice for both implementation and performance reasons. Therefore, netmap-based libpcap could be utilized for this thesis for compatibility and performance reasons.
    \section{Data storage} \label{analysis:storage}
        Initially, as it may seem, the most critical part is real-time packet capture. Although, the real bottleneck in whole data processing is real-time data storing with acceptable time delay. Storing captured data includes parsing raw data and send them to a remote database server for further data analysis. This section analyzes considered database systems and options.
        \subsection{SQL versus NoSQL} \label{analysis:storage:sql}
            Using a Structured Query Language (SQL) database requires knowing the data model of the expected data - Relational Database Management System (RDBMS). This would require a complex data model of all possible fields of network protocols. SQL database stores full entries of data despite multiple empty fields, which produces extra disk space usage.\par
            However, Non-relational Structured Query Language (NoSQL) database provides high flexibility with its data and a faster search. Data can be stored in JSON format, which makes it directly compatible with numerous parsers and any data manipulation. NoSQL databases are also characterized as key-value pair database systems, such as Redis database, which is a simple caching database, MongoDB or Elasticsearch.
        \subsection{ELK stack} \label{analysis:storage:elastic}
            ELK stack\footnote{\url{https://www.elastic.co/elk-stack}} stands for \emph{Elasticsearch}, \emph{Logstash} and \emph{Kibana}, but at this point there are more possible components of the ELK stack (e.g. \emph{Filebeat}). The database component Elasticsearch is a NoSQL database with no fixed data model. In comparison with a SQL database, where data is stored in records and tables, Elasticsearch stores data in documents and indices. Communication with an Elasticseach database is through various APIs using well-known HTTP methods GET, POST, PUT and DELETE is in JSON query format.\par
            An Elasticsearch index is populated by documents in JSON format and is defined by its settings API and mapping API. Via settings, the default number of shards\footnote{Indices may be split into multiple sub-indices called shards.} and the number of replicas\footnote{Shard copies, functioning as a failover. The number of replicas represents the number of copies of each shard.} \cite{docs:elastic:terms} is defined. The mapping defines the document expected field's value type, but in case of lacking a concrete field mapping, a document insertion does not fail.\par
            \begin{figure}
                \centering
                \includegraphics[scale=0.5]{logstash-filebeat}
                \caption{ELK stack setup including Filebeat \cite{image:elk}.}
                \label{figure:storage:elk}
            \end{figure}
            Logstash provides parsing, filtering and queuing data streams from multiple sources to be inserted into Elasticseacrh database (see~\autoref{figure:storage:elk}). It is useful for data enrichment and modification before it is inserted in bulk\footnote{Documents wrapped in batches sent via one HTTP request \cite{docs:elastic:bulk}.} requests, rather than single documents. In its configuration are data input streams' specifications, filter clauses including transformations and output stream, which is usually the Elasticsearch database. It reads various input streams like Filebeat, Elasticsearch or raw TCP data stream.\par
            In contrast, Filebeat is a lightweight component reading raw inputs, such as system log files or TCP raw data stream, which are redirected either directly to Elasticsearch or Logstash for more transformations and queuing purposes.\par
            Kibana is an optional component of the ELK stack capable of visualizing and monitoring data in Elasticseach (see~\autoref{figure:storage:elk}). It is a user-friendly Elasticsearch interface, which abstracts the request queries when creating a visualization. For example, Kibana could serve as the Graphical User Interface (GUI) of the data stored in the database for a network monitoring team of specialists. Besides, it recognizes a compatible timestamp formatted field for multiple time period selections from any index or a specific data set. Moreover, to extend a field value, or creating a new field (visible only for Kibana) is possible by using scripted fields feature. All these features, creating visualizations or querying data in a NoSQL fashion are all advantages of using Kibana. Similarly, as other ELK stack components, Kibana has a configuration file for specifying the Elasticsearch database.\par
            In comparison with a SQL database, Elasticsearch documents are populated with only provided fields, despite being defined in the mapping or not. Whereas, SQL database does always insert into all fields even if they are empty. This Elasticsearch advantage saves space and makes the search elastic and fast. Utilizing ELK stack would require an external system connected to the sensor, or it could be residing on the same physical machine.\par
        \subsection{Redis} \label{analysis:storage:redis}
            As an in-memory solution, where data analysis would take place as a part of the program and not as an external system connected to it, \emph{Redis}\footnote{\url{https://redis.io/}} could be the solution. Redis is widely used as a caching database \cite{docs:redis}, which would require analyzing and implementing the visualization of data as a part of the final program. In addition, the data received would not be stored, rather cached in the Redis database.
        \subsection{Sumamry} \label{analysis:storage:conclusion}
            Since SQL databases are not suitable and Kibana provides the visualization tool for received data at an arbitrary time period from the past, the ELK stack could be the right database system for this thesis.
    \section{Data visualization} \label{analysis:data}
        The ELK stack component Kibana does data visualization. It meets all visualization requirements, such as selecting a specific time period, creating bar graphs, heat maps or trend lines and updating all as new data is received. This section discusses the data worth visualizing for further analysis. We will consider all layers of the TCP/IP model - \hyperref[analysis:data:network]{Network layer}, \hyperref[analysis:data:transport]{Transport layer} and \hyperref[analysis:data:application]{Application layer}.
        \subsection{Network layer} \label{analysis:data:network}
            Collected data at this layer include endpoint nodes, source and destination IP address, the nested protocol of the higher layer, the size of the packet at hand and the Time To Live (TTL) field. The IP address is a valuable field, containing multiple properties of the endpoint. The IP address provides the location of the node, Autonomous System Number (ASN) of a specific Internet service provider, whether its a unicast, multicast or broadcast or it being a private or public IP address (regarding IPv4). Moreover, the Total length field (16-bit packet length) indicator can be used to detect large data transmissions. If the length is and very frequent, it could indicate unlawful activity or predict link failure for it would not withstand that high packet rate.\par
            \begin{figure}[h]
                \centering
                \includegraphics[scale=0.7]{osfingerprinting}
                \caption{OS fingerprinting with known IPv4 fields \cite{web:osfinger}.}
                \label{figure:data:osfinger}
            \end{figure}
            Additionally, according to an article on operating system (OS) fingerprinting with packets \cite{web:osfinger}, the TTL, packet size, flags and other option fields in the IPv4 protocol header can be used to determine the OS of the source endpoint (see~\autoref{figure:data:osfinger}). Based on this assumption, the network traffic is analyzed from more security concerned point of view, by grouping hosts by OS.
            Other frequent network layer protocol Internet Control Message Protocol (ICMP), as the name defines, is used in various network use-cases for notification purposes. For example, \emph{traceroute} protocol utilizes a property of a network device responding with an \emph{ICMP Time Exceeded} message when the TTL counter reaches zero. ICMP is also used in routing protocols, such as RIPv2, and is most recognized as protocol utilized by \emph{ping} program used for debugging connectivity issues.
        \subsection{Transport layer} \label{analysis:data:transport}
            The transport layer provides more information on the communication, specifically port numbers, which identify the service over which data is transmitted. Most recognizable Transport layer protocols are Transmission Control Protocol (\hyperref[analysis:data:transport:tcp]{TCP}) and User Datagram Protocol (\hyperref[analysis:data:transport:udp]{UDP}). TCP is used for services requiring reliable transmissions and does not require fast delivery, whereas UDP provides fast transmit rates at a cost not being reliable.
            \subsubsection{TCP} \label{analysis:data:transport:tcp}
                The TCP protocol transfers services like SSH, FTP, Telnet, HTTP(S), BGP, SMTP and more. TCP header includes the source and destination port numbers, where usually one is higher (client public port 49152 - 65535), and the other is lower (server designated port 0 - 1023). According to this, it is possible to monitor when a well-known service is being used in the network or when two endpoints are communicating with public ports. There are various indicators considering port numbers and the client-server model.\par
                Furthermore, the TCP flags may be used to detect a session has opened or closed with the SYN and FIN flags respectively. When following the standardized three-way handshake, the SYN flag stands for "synchronize" and should indicate a session start. The FIN referring to final, finish or finalize indicates the session close. This is only a brief explanation, and of course, there are more TCP flagged packets to be sent between.
            \subsubsection{UDP} \label{analysis:data:transport:udp}
                UDP is a much simpler protocol with minimum header fields. It is the source and destination port numbers, length of corresponding UDP header with data and an optional checksum field. UDP is used by DNS, DHCP, TFTP, NTP, and more services, which in comparison with TCP, provide fast file transfer service (e.g. TFTP) or general service transparent for a basic user (e.g. DNS, DHCP or NTP). Like all services, these have specific port numbers too, which can be read from packet capture even if the communication is encrypted\footnote{Communication is encrypted on the application layer.}. The UDP datagram length can be used for UDP datagram size histograms and statistics or detecting a high data transmission on the network.
        \subsection{Application layer} \label{analysis:data:application}
            Since most network traffic on this layer is encrypted (e.g. SSH or HTTPS), there are minimum unencrypted protocols, which data could be analyzed or visualized. Unencrypted services include HTTP, Telnet over port 23, DNS, DHCP, FTP, TFTP and more. Raw data of these protocols could be used for deeper analysis.\par
            \subsubsection{Unencrypted and encrypted} \label{analysis:data:application:encr}
                In the scope of this thesis, DNS packets may be the most valuable UDP-related application service for analysis. Detecting and monitoring DNS communication has high-security reasons. A possible amplification attack is realized by DNS packets.\par
                Furthermore, HTTP, FTP, and TFTP are unencrypted data transmitting protocols, which could carry potentially valuable information. For example, HTTP protocol could be used as the insecure communication between client and web server, database or any API. Intercepting this traffic could provide statistics of successful or failed requests ergo connections. File transfers over TFTP or FTP disclose all data, which is part of the transmitted message. For statistical reasons, it is not beneficial to capture this data, but detecting these protocols indicates usage of insecure transmission.\par
                Others protocols (e.g. SSH and Telnet) are communication protocols acquiring connection with a host device for remote control. SSH is a secure communication protocol, which could be analyzed even when encrypted \cite{web:ssh}, but it is complicated. Nevertheless, the SSH communication is analyzed by detecting TCP protocol with source or destination port 22. In contrast, Telnet may be used for the same purposes as SSH, but it is not advised for it is an unencrypted communication channel. All sensitive data, such as user names, passwords or file system contents must be transmitted over to remote control terminal and thereby disclosing it all on the way.
    \section{Existing solutions} \label{analysis:solutions}
        Existing software solutions \hyperref[analysis:solutions:moloch]{Moloch}, \hyperref[analysis:solutions:wireshark]{Wireshark} and \hyperref[analysis:solutions:solarwinds]{SolarWinds} partially depict the problem at hand.
        \subsection{Wireshark} \label{analysis:solutions:wireshark}
            \emph{Wireshark}\footnote{\url{https://www.wireshark.org/}} is a tool using standard libpcap library used for live deep packet analysis, pcap file analysis and following connection streams. It includes protocol hierarchy statistics, I/O graph view of received packets per second, endpoint and network session statistics and complex filtering options. Wireshark understands multiple protocols, outputs live packet capture and hierarchically parses packets. Wireshark does not provide the required data visualizations.
        \subsection{Moloch} \label{analysis:solutions:moloch}
            \emph{Moloch}\footnote{\url{https://molo.ch/}} is similar to Wireshark in the way of reading pcap files and life network traffic. It utilizes Elasticseach cluster for fast search operations and captures data with PF\_RING module. Moloch provides network sessions statistics, unique value occurrence in sessions (SPI view or graph), network connections graph view of search results and Elasticsearch cluster and Moloch capture node statistics. Although, various visualizations of received data is not included.
        \subsection{SolarWinds} \label{analysis:solutions:solarwinds}
            Specifically \emph{SolarWinds Deep Packet Inspection and Analysis tool}\footnote{\url{https://bit.ly/2FUWBRn}}, processes each received packet, but summarizes the gathered information to protocol statistics and packet classifications. Includes network latency testing in a network segment for troubleshooting purposes. Does not provide deeper packet analysis (e.g. various protocol header fields) or arbitrary visualizations of captured data.\par
\chapter{Problem solution} \label{solution}
    The solution to the analyzed components and merging it to one functioning system is described in the following chapter. The system specification, including its properties and use cases, is outlined in \autoref{solution:spec}. The design of the solution and the overall system architecture is introduced in \autoref{solution:design}. The particular implementation techniques and class model is described in \autoref{implementation}.
    \section{System specification} \label{solution:spec}
        The final system must include the network sensor implanted in the network for capturing packets and the ELK stack, which as the sensor is on a Linux machine. The sensor must then process and parse the received packets into a compatible JSON format for storing it to the database system via an API call.\par
        The key processes that need to be included are as follows. Choosing an interface as the source of received traffic and specifying the direction (outgoing, incoming or promiscuous mode), specifying the database destination with an IP address and a port. Furthermore, it must notify the user with potential errors or successful tasks (such as initialization of the sensor) in the standard log file in the designated system directory. The packet capture and further processing must not create a bottleneck and be ideally processing at wire speed.\par
        Data visualizations include various line graphs, bar graphs, heat maps, and periodically updated trend lines as new data is received. The final data set must include all desired protocol header fields and packet metadata such as the timestamp of the received packet, source host of the received data and source interface of that host. The database system should not delay the data stream. The requested visualizations are listed and briefly explained in \autoref{sol:design:elk:vis} part \emph{Visualizations and database setup}.
    \section{Design} \label{solution:design}
        \begin{figure}
            \centering
            \includegraphics[scale=0.5]{architecture}
            \caption{System architecture model.}
            \label{figure:sol:architecture}
        \end{figure}
        \subsection{ELK stack initialization} \label{solution:design:elk}
            Starting from the top of the system architecture model, the ELK stack setup is a prerequisite for functional sensor sending data to the database. The deployment of the ELK stack on a remote or local server is handled by a series of \emph{Ansible}\footnote{\url{https://www.ansible.com/}} roles. It installs each ELK stack component, including setting up required configuration files. Every component configuration is described in the following subsections. 
            \subsubsection*{Elasticsearch}
                Configuring Elasticserach requires setting up a new index for data and filling out the configuration file located in \emph{/etc/elasticsearch/elasticsearch.yml} (see~\autoref{lst:sol:elastic:conf}). After correctly configuring Elasticsearch, the index template is created via \emph{curl} program or via Kibana developer's tools (see~\autoref{lst:sol:mapping}).
                \lstinputlisting[language=Clean, style=appendix, label=lst:sol:mapping, caption=Create index template with index field mapping.]{src/create_template}
                The mapping of the index needs to include all fields. The proper way is to design it in a object form (e.g. \emph{source} object mapping in \autoref{lst:sol:mapping}). Mapping will correspond to real life data types, meaning an IP address has the type \emph{ip} or a geographical coordinates is of type \emph{geo\_point}. All mapping data types are listed in the Elasticsearch documentation\footnote{\url{https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html}}.
                \lstinputlisting[language=Clean, style=appendix, label=lst:sol:elastic:conf, caption=Elasticsearch configuration in YAML format]{src/elastic.conf}\par
                \emph{Path.logs} and \emph{path.data} specified the logging base directory and the path to archoved index data respectively. Most important is the \emph{network.host} in the example, which specifies that any remote system can access the database at specified port. This security vulnerability will be resolved by a firewall setting on the ELK stack server, allowing only the sensor host and localhost connections.
            \subsubsection*{Filebeat}
                Filebeat is configured with a host IP address and a port accepting TCP data. The JSON decoder in Filebeat is notified of receiving JSON formatted data via a tcp stream. All received data will be logged to corresponding log file. The output stream will be forwarded to Logstash socket specified by \emph{output.logstash.hosts} (see~\autoref{lst:sol:filebeat:conf}). In the background, filebeat harmonizes the data by filebeat specific fields. This example configuration sets a functional Filebeat receiving and forwarding JSON objects separated by \emph{new-line}.
                \lstinputlisting[language=Clean, style=appendix, label=lst:sol:filebeat:conf, caption=Filebeat configuration in YAML format.]{src/filebeat.conf}
            \subsubsection*{Logstash}
                Referring to the configuration (see Appendix~\autoref{lst:logstash:config}), Logstash is set up to listen on an arbitrary port and tagging the input. The filter clause removes undesired fields and renames fields for data field misconception elimination. The original \emph{source} field holds the host address of the source system sending data to Filebeat. The nested JSON clause creates a JSON object of the \emph{message} in JSON string type. Once the JSON object is created, the \emph{message} field may be deleted, and a final field is added to mark the future document with an identification of the filter clause used. The output clause sets the forwarding destination, which is the Elasticsearch database API, target index and document type.
            \subsubsection*{Kibana}
                Kibana is configured by a configuration file \emph{/etc/kibana/kibana.yml}. The default configuration (see~\autoref{lst:sol:kibana:conf}) from the installation is correct, since both Kibana and Elasticsearch will coexist on the same physical machine. The received data can be recognized and visualized by Kibana after setting up the index pattern and timestamp. New index pattern is created under Management \texttt{->} Kibana \texttt{->} Index Patterns only after the index occupies at least one document. This limitation can be bypassed by using the Kibana REST API.
                \lstinputlisting[language=Clean, style=appendix, label=lst:sol:kibana:conf, caption=Kibana sufficient default configuration.]{src/kibana.conf}
            \subsubsection*{Visualization and database setup} \label{sol:design:elk:vis}
                With the index pattern set Kibana executes the requested visualizations on indices matching the index pattern. Each visualization is periodically refreshed as new data is stored. Visualizations are grouped in dashboards (see Appendix~\ref{appendix:sol:dashboard}), which serves as the main page for further data analysis and monitoring. Also, Kibana includes \emph{Developer tools} to request data with a JSON formatted query for fast search and the \emph{Discover} page which shows the latest received data. Other sections are not in the scope of this thesis.\par
                Following the required visualizations, each is visualized by the most suitable representation:
                \begin{itemize}
                    \item \emph{"Services in use"} are two line graphs (source and destination) displaying the count of packets based on the service (port number). Each line is representing a service independent of the transport protocol. The x-axis is the time at which the packets were captured. By filtering the services, this visualization is for monitoring \emph{"specific service(s)"} too.
                    \item \emph{"Geographical location of end nodes"} are two maps (source and destination of traffic) distinguishing multitude by color. The country is resolved from IP address either by the sensor or at the visualization tool.
                    \item \emph{"Packet size ranges"} displays UDP, TCP, ICMP, etc. protocol multitudes as a heat map, pie graph, and line graph. Heat map groups by packet size ranges on one axis and protocol on the other. Pie graph depicting percentage ratio. Line graph specifically showing the multitude of protocols at a given time, where each line represents a single protocol.
                    \item Time-based \emph{"packet size model"} is a bar graph with time axis split by packet size ranges. The ranges specify the small packets, average sizes, and large data packet sizes.
                    \item \emph{"Packet flow"} is a line graph with a time axis. Dots represent the total count of packets at a particular time and a line representing the moving average of the values. It effectively shows the growth or descent of packet flow.
                    \item \emph{"Visualization filters"} include the protocol filter, packet size range select and differentiating between receiving and transmitted (RX and TX) packets. This is not the filter limitation, but it depicts the most useful ones, and others are possible.
                    \item \emph{"Nodes' communications"} is a histogram or tag cloud displaying the most active connections between two hosts (IP addresses). 
                    \item \emph{"Statistical model"} of packet sizes is a line graph showing various statistical metrics, such as count, median, minimum, maximum or standard deviation.
                \end{itemize}
                
                To completely automate the initialization process and ready the visualizations all must be functioning when the visualization tool is opened. For Elasticsearch and Kibana, it requires loading the index template, create visualizations, index patterns and dashboards. The reason for automation is if the system is duplicated or moved on different machines. It requires to preserve all settings, configurations, and visualizations.\par
                The solution is to use Ansible for deploying the ELK stack components on the target machines. These Ansible roles deploy configured ELK stack components with functioning pipeline ready to receive data on Filebeat, which forwards them to Logstash and Elasticsearch. Missing are the visualizations, which need an additional deploying mechanism to ready the visualizations and filters in Kibana. Kibana has its REST API used for importing and exporting of saved objects\footnote{Saved objects include all index patterns, visualizations, dashboards and saved searches created in Kibana.}. \autoref{lst:sol:design:init_kibana} briefly depicts the necessary steps for initializing the Kibana environment.                
                \lstinputlisting[language=Clean, style=appendix, label=lst:sol:design:init_kibana, caption=Initialize Elasticsearch and Kibana.]{src/kibana_api}
                
        \subsection{Sensor} \label{solution:design:sensor}
            The sensor is a Linux program utilizing netmap-based libpcap (supported by test results in \autoref{analysis:testing}) capturing network traffic, storing parsed packets to database and logging progress to local or remote rsyslog server.\par
            Utilizing libpcap, the sensor captures traffic in simple receive, transmit or promiscuous mode and distinguish each packet by this indication. Each received packet is be parsed in the scope of required protocols up to the Transport layer excluding the data payload (headers only). IP addresses are resolved in geological location database for country distinguishing. Parsed and harmonized packet data are converted to JSON objects. A suitable JSON library is used for parsing the packets to JSON structures, which are sent out as raw TCP data to Filebeat. Whole process is simplified in \autoref{figure:sensor:process}.
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.35]{sensor_process}
                    \caption{Sensor packet parsing and processing}
                    \label{figure:sensor:process}
                \end{figure}
            \subsubsection*{Main process} \label{solution:design:process}
                \begin{figure}[h]
                    \centering
                    \includegraphics[scale=0.57]{datamodel}
                    \caption{Sensor class model.}
                    \label{figure:sol:datamodel}
                \end{figure}
                The class model briefly depicts the most crucial parts of the sensor class design (see~\autoref{figure:sol:datamodel}). The sensor is configured by a configuration file, specified by the user. Both interface specification and database connectors will be included in this configuration file. Configuration file is validated before any initialization is performed. More precisely the configuration file specifies:
                \begin{itemize}[noitemsep]
                    \item target interface and the capture direction
                    \item target Filebeat host and port
                \end{itemize}\par
                The format is in YAML for clear interpretation, which requires a YAML parsing library reading the preferences to program structures. The configuration file is read on the start of the program, and any further modification does not affect the running process.\par
                Setting up a libpcap capture handle comprises of the following preferences and is followed by opening the handle for active capture processing each packet in a callback function.\par
                \begin{itemize}[noitemsep]
                    \item resolving the target interface to existing interface and retrieving MAC and IP address
                    \item attempt to set snapshot length, immediate mode, and specific buffer size
                    \item set capture direction
                \end{itemize}\par
                In the callback function, the packets are broken down to protocols using a packet parsing library. Each packet is harmonized and converted to JSON string. A suitable library for producing JSON regarding performance \cite{git:benchmark:json}, such as parsing time, memory in use and time it takes to stringify is \emph{RapidJSON}\footnote{\url{http://rapidjson.org/index.html}}. After packet harmonization and parsing the JSON strings are sent through TCP socket to Filebeat.
            \subsubsection*{Configuration file} \label{implementation:sensor:config}
                Configuration file must be located in the designated directory for program configurations - \emph{/project\_root/resources/traffcol.yml}, where \emph{traffcol} is an abbreviation for traffic collector. It is the main configuration file loaded by the program.\par
                The configuration file must include the following fields. The source interface name must correspond to the name listed by \emph{ip link} or \emph{ifconfig} commands. The possible capture direction modes are "out" for outgoing packets, "in" for incoming packets and "promisc" for promiscuous mode. The Filebeat connection specification must be a resolvable host and a port number.\par
                In case of a missing component, the system logs it as an error and request correction. For sample configuration and default configuration refer to the Appendix \autoref{lst:sensor:config}.
            \subsubsection*{Initialization}
            For sensor initialization, it requires a configuration file with all mandatory preferences. Of course, the prerequisite is the ELK stack initialized and ready with visualizations waiting for new data. Optionally a running \emph{rsyslog}\footnote{Rsyslog stands for rocket-fast syslog, and it is the decedent of syslog.} server or syslog accepting local logs. Setting up (r)syslog server can be simple as configuring a destination file and accepting logs from a local source if it's on the same machine.
            
\chapter{Implementation} \label{implementation}
    According to all specifications and speed requirements, the sensor is programmed in C++, well compatible with netmap-based libpcap. The sensor consists of a specific interface as a source of network capture, packet parsing, logging, and database connection. Referring to \autoref{figure:sol:architecture} the implemented component is the sensor with logging to files. The respective configuration files configure the ELK stack components. A script initializes Kibana and Elasticsearch via specific APIs.
    \section{ELK stack deployment and setup} \label{implementation:elk}
        Both deployment and setup are designed as a series of Ansible scripts and a single bash script. All ELK stack components are deployed on Debian-based Linux machines (e.g. Ubuntu Server).
        \subsection{Deployment} \label{implementation:elk:deploy}
            Ansible a remote command execution automation tool consisting of various modules (e.g. shell, package, copy, etc.). It utilizes SSH connection for remote deployment, which is the only prerequisite of target machine. A series of Ansible roles\footnote{\url{https://github.com/tomas321/ansible-roles/tree/master/common/elk}}, for each ELK stack component, are executed to fully configure and enable ELK stack. Each component is a Java application, so a requirement is to install a specific version of Java. An exemplary role for deploying Elasticsearch is listed in \autoref{lst:implementation:elastic:deploy}. All roles are documented in the repository.
            \lstinputlisting[language=Clean, style=appendix, label=lst:implementation:elastic:deploy, caption=Elasticsearch Ansible role overview.]{src/elastic_role}
        \subsection{Setup} \label{implementation:elk:setup}
            ELK stack components are configured as shown on \autoref{solution:design:elk}. All configurations are derivatives from default configurations because no extended plugin features are required. For monitoring the data in Kibana, an index template with field mapping is created in Elasticsearch and all visualizations in \autoref{sol:design:elk:vis} were configured directly in Kibana. Just as described in \autoref{sol:design:elk:vis}, the Kibana objects are retrieved and ready for importing to an existing instance of Kibana via a script (see~\autoref{lst:sol:init_kibana}).
            \lstinputlisting[language=Clean, style=appendix, label=lst:sol:init_kibana, caption=Initialize Elasticsearch and Kibana custom prerequisites.]{src/initialize_kibana}
            Initialization script puts the index template to Elasticsearch and imports the visualizations via the Kibana REST API. Kibana region map visualizations are not fully equipped to mark all known country codes\footnote{Regarding country codes also include continent or other non-country codes \cite{geoip:country_codes}.}, therefore the script issues to disable a possible warning about not being able to mark non-country codes.\par
            The \emph{Nodes' communications} histogram visualization required extra script (see~\autoref{lst:implementation:scriptedfield}) to create in the Kibana environment. This scripted field is part of the index template inserted by the Kibana initialization script.
            \lstinputlisting[language=Java, style=appendix, label=lst:implementation:scriptedfield]{src/scripted_field}
            It creates a new field representing a connection between two nodes independent of the packet direction (source to destination and vice versa) by comparing the IP address string representations to maintain the order.
    \section{Sensor} \label{implementation:sensor}
        Sensor is implemented as a single thread program, where each component will be viewed as an object (see~\autoref{figure:sol:datamodel}). The Configuration class loads a YAML configuration file from the \emph{"project\_root/resources/"} directory to specific C++ structures - \emph{db\_config, iface\_config} and validates (see~\autoref{implementation:sensor:cfgval}) the file's format. Configuration file is parsed utilizing \emph{yaml-cpp}\footnote{\url{https://github.com/jbeder/yaml-cpp}} library. Components Interface\_connection and Database\_control are created with corresponding configuration structures, which contents are verified by connection attempt to database system, opening given interface file descriptor with specified preferences. Any errors are logged and the main process is terminated.
        \subsection{Configuration file validation} \label{implementation:sensor:cfgval}
            A dynamic validation algorithm for YAML configuration file requires another YAML file specifying the configuration file structure and available fields. The algorithm crawls through the specification file and accordingly validates the fields in the actual configuration file. The only thing it checks is whether mandatory fields are not left out and if it is structured the way it should be. The algorithm is simplified in \autoref{lst:implementation:cfgval}.
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:cfgval, caption=Algorithm for configuration file validation utilizing the YAML parsing library.]{src/validate_config}
            Calling \emph{validate\_key} (see line 11 in \autoref{lst:implementation:cfgval}) takes the current key of the specification file and a boolean value specifying if it's mandatory. Failed test throws an exception and the program initialization stops. 
        \subsection{Packet capturing} \label{implementation:sensor:cap}
            Capture handle in libpcap is well configurable, though it is system dependent and not all preferences are available. All function calls are listed in \autoref{lst:implementation:pcap} and worth mentioning are performance oriented settings according to Libpcap manual page \cite{man:pcap}. Snapshot length of 300, minimizes the CPU time and evades the addition packet reassemble and it should be enough to bound the maximum size of packet headers even in case of tunneling such as \emph{IP in IPv6}\footnote{Size of such packet header might be 24B Ethernet + 40B IPv6 + optional IPv6 extension headers multiple of 8B (e.g. 40B) + tunneled IPv4 of maximum 60B + maximum 60B TCP = 224 \cite{man:ipv6}.} and vice versa. Arriving packets are processed as soon as they arrive with setting the immediate mode. To minimize the packet loss, the buffer size is set to a maximum of 2 GB. The capture direction is set using the libpcap filters by filtering by source and destination MAC address (e.g. \emph{ether dst 10:e3:aa:00:00:12}).
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:pcap, caption=Packet capture handle setup API calls.]{src/pcap}\par
            Correct settings are followed by opening a capture session and looping for an infinite number of packets. Each packet is handled in a callback function passing the packet to the parsing process.
        \subsection{Packet parsing} \label{implementation:sensor:parse}
            \begin{figure}[h]
                \centering
                \includegraphics[scale=0.5]{parsing}
                \caption{Packet parsing library class model.}
                \label{figure:sol:parselib:model}
            \end{figure}
            Firstly, each packet is parsed based on this class model (see~\autoref{figure:sol:parselib:model}) by simple algorithm (see~\autoref{lst:implementation:parselib}). Parsing packet to \emph{Parsed\_packet} object goes through supported layers one by one until acceptable last protocol header is reached (e.g. TCP header). Using such custom parsing library is minimalistic, because it does no extra object creation and is independent of third party libraries. This parsing process is the backbone of understanding raw packet bytes. Called function \emph{parse\_header} parses a given layer and increases the offset from the first byte of raw packet dynamically (IHL field in IPv4) or statically.
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:parselib, caption=Raw packet parsing process.]{src/packet_parse}
            
            \emph{RapidJSON} library provides the \emph{Simple API for XML} (SAX API), which includes a JSON generator \emph{Writer}. Writer converts keys and values into JSON in a procedural manner (see~\autoref{lst:implementation:parsing}). Keys specified in the output JSON correspond to the Elasticsearch index mapping. Parsing is expected to execute without errors since the input is a Parsed\_packet object structure and the output is a JSON string. The sensor has a higher layer API for constructing JSON to support multiple value types. JSON parsing solution sampled in \autoref{lst:implementation:parsing} encapsulates, even the minimum, complexity in a small Json class. It's based on utilizing the C++ function templating as seen in lines 15 through 20.
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:parsing, caption=Packet parsing to JSON format.]{src/parsing}
            In this section the packet data is harmonized by geological location from static \emph{GeoIP} database file utilizing a library\footnote{\url{https://github.com/maxmind/geoip-api-c}} for querying such files with source or destination IP addresses. In addition, when knowing the IP addresses the data is compared to the capture interface address and store the direction of the packet (either RX or TX).
        \subsection{Committing packets to ELK stack} \label{implementation:sensor:commit}
            Committing to the database is realized by a TCP socket. Prerequisites are a connection to Filebeat and setting a keep-alive session. The destination host is specified in the configuration file in a hostname format or an IP address. In the case of hostname, the IP address is resolved by \emph{gethostbyname} system call. A successful address resolution the socket attempts a connection to a specific port. This is the initialization process, and on the success the newly created object holds the active socket file descriptor. Sending the JSON string requires new-line terminated data (line 12 in \autoref{lst:implementation:parsing}).    
        \subsection{Logging} \label{implementation:sensor:logging}
            Logging is realized by local \emph{rsyslog} server configured either manually or utilizing Ansible\footnote{\url{https://github.com/tomas321/ansible-roles/tree/master/common/rsyslog}} included the the digital submission. Rsyslog and generally syslog server distinguishes sources by facilities \cite{man:syslog} and sensor logs to facility LOG\_LOCAL1 (see~\autoref{lst:implementation:logging}).
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:logging, caption=Opening syslog and API function for logging.]{src/logging}
            LOG\_CONS - Logs syslog failures to system console.\\
            LOG\_NDELAY - No delay opening the syslog connection.\\
            LOG\_PID - Log process ID (PID) with each message.\par
            Rsyslog is configured in a configuration file (\emph{/etc/rsyslog.d/custom.conf}) with specifying the facility, log levels logged, log message format and a destination file (see~\autoref{lst:implementation:rsyslog}).
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:rsyslog, caption=Rsyslog configuration file.]{src/rsyslog}\par
            To resolve ever-increasing log file size, rsyslog provides log rotation (see~\autoref{lst:implementation:rsyslog}). Logs are rotates only if not empty, each log is rotated 4 times and the rotation is executed when the file size exceeds 10k bytes. After rotation the new log file is created and the old is compressed with no delay (otherwise it compresses the file after next rotation). To reset the file descriptor of the log file for rsyslog the systemd service is restarted right after the rotation.
            \lstinputlisting[language=C++, style=appendix, label=lst:implementation:logrotate, caption=Rsyslog log rotation configuration.]{src/logrotate}
\chapter{System tests} \label{tests}
    The subject of testing were mostly all features and functionalities the program has. The expected behavior is to be able to configure capture direction, start packet capture and log all progress to a local rsyslog server. Log files should rotate as specified in the log rotation configuration file. Finally, the ELK stack should be configured for storing captured packets, including visualizations in Kibana with minimal hands-on configuring.
    \section{Whole system test run} \label{tests:one}
        Testing the system as a whole consisted of starting the packet capture, and monitoring for real-time statistics and analysis in Kibana.\par
        The sensor was capturing packets and successfully sent the data in correct format and structure to Elasticsearch. The Logstash component has correctly parsed the JSON string to JSON and sent the data to Elasticsearch index with the expected suffix (current date). The Elasticsearch index template correctly templated the data types of the destination index. Finally, the data was visualized in the dashboard (see~\autoref{figure:dashboard}) as more data was arriving (real-time analysis). From top to bottom and left to right the dashboard includes filters, the overall count of captured packets, a trend of the packet flow, time characteristics of protocols encapsulated by IP layer followed by its percentage representation. Next, are the region maps displaying the source and destination of traffic\footnote{Since the capture was set to promiscuous mode the maps are similar.}. Below is the distribution of packets to size ranges represented as a heat map with IP protocols and time distributed. Next pair is the packet count with source and destination service (in port numbers). On the very bottom are the top 10 node communications arranged in a way to not take into account which is the source and which destination aside from the statistical model of the packet lengths.
        \begin{figure}
            \centering
            \includegraphics[scale=0.2]{final_dashboard}
            \caption{Screenshot of the final dashboard.}
            \label{figure:dashboard}
        \end{figure}
    \section{Deployment}
        On a newly installed Linux system (Ubuntu server 18.04) Ansible deployed the ELK stack preconfigured components, rsyslog server with log rotation and sensor dependencies excluding netmap and netmap-based libpcap library. After that, Filebeat was ready for accepting data and sensor was ready for manual compilation with netmap download and installation.
    \section{Logging}
        The log file was successfully created in the specified right when the sensor started. After the log file was big enough the log rotation system cron job would rotate the log file. To issue the log rotation, the \emph{logrotate} either forces or attempts the log rotation. As a result, the log file has rotated, created a new file, compressed the old log file and restarted the rsyslog service.        
\chapter{Conclusion}
    Multiple factors are to be taken to account since the system is a functional capture mechanism with a connected existing monitoring tool. Even though the packet capturing is well analyzed, and multiple mechanisms are compared, the solution is implemented with the libpcap library. The reason was to make the system more compatible across platforms. Sensor program may be linked to various libpcap versions, such as netmap or PF\_RIING based libraries. The downside is the performance compared to the native API of both of these frameworks. Nevertheless, utilizing the netmap-based libpcap is a fair compromise to compatibility and performance.\par
    As for the other part of the system - database and visualization tool alone brings fast search from the database and vast visualization features. All captured network traffic is visualized in real time. However, insertion to Elasticsearch is not as fast as the capture mechanism can be, which raises the issue of bottlenecks and losing data. This is most certainly where the system can be improved by either enlarging the Elasticsearch cluster to more nodes and splitting the load. Other solutions may be to implement a buffered monitoring tool with an additional external storage system. This way every new packet would update each visualization and be stored to the database. Nevertheless, Kibana is the right tool for visualizing data in Elasticsearch even in real time, to detect possible network abnormalities or attack attempts.\par
    Overall, the system is well organized and documented in source code as well in installation and user guides. In addition, most of the system is deployable by Ansible to simplify the installation on target systems. As is it for most programs, the sensor logs its progress to the local syslog server. For future work the sensor should be fully configurable, meaning more capture options specified by the user, such as filter packet capture, logging to a remote syslog server or adding more IP address harmonization data (ASN, city or geological coordinates). Besides, the sensor has no install target configured in its make file, so for future work, it could be fully installed on the system as a system-wide executable or even as a systemd service.\par
    In comparison to mentioned existing solutions (see~\autoref{analysis:solutions}) this solution has more of the visualization part, which is the most important part of security even with the acceptable delay. A proper visualization targeting the right data can detect most of network traffic spikes. Most of the existing solutions are not dependent on an external database system but work as a single tool for monitoring and searching network packets. This sensor may be theoretically deployed multiple times on different machines and with minor modifications of the Filebeat configuration scaling up the capturing mechanism to distributed packet capture system with a centralized database and monitoring tool.

\chapter{Resumé}
    Zber a analýza o sieťovej prevádzke má dávať odpoveď na otázky štýlu, kedy, kto, koľko, kde a od kiaľ komunikoval v sledovanej sieti. Cieľom je implementovať systém zberu sieťovej prevádzky v systéme typu UNIX/Linux s úložiskom dát a následnou vizualizáciou a analýzou dát. Zber dát spočíva v čitaní sieťových rámcov zo sieťového adaptéra (NIC) a v zmysle zadanie je potrebné zanalyzovať a porovnať rôzne mechanizmy. S cieľom jednoduchosti a praktického využitia bola zvolená pytónová knižnica \emph{scapy}, kompatibilita a štandard reprezentovala knižnica \emph{libpcap}, rýchle a efektívne riešenia prestavovali prostredaia \emph{PF\_RING} a \emph{netmap} a nízkoúrovňový soket \emph{PF\_PACKET}.\par
    Každý z týchto mechanizmov poskytuje iné výhody ale aj nevýhody. Scapy je vhodný pre komplexné skladanie paketov, ale chýba mu rýchlosť a jednoduchosť. Libpcap je kompatibilný a často nainštalovaný naprieč väčšiny platforiem, ale pri vyšších tokoch zahadzuje pakety. PF\_RING je prostredie pre rýchly zber sieťovej prevádzky závislý od Intelových sieťových adaptérov a vlastných jadrových modulov. Netmap je prostredie presadzujúce rýchlosť nizkoúrovňových fundamentálnych zmien v štruktúre zásobníkov a je závislí od jadrového modulu. PF\_RING aj netmap obsahujú vlastnú vylepšenú knižnicu \emph{libpcap} mapujúcu natívne API volania na štandardné libpcap volania. Na záver, PF\_PACKET je protokolová rodina využívaná libpcapom zabezpečujúca priame posielanie či príjmanie čistých Eternetových rámcov.\par
    Spomínané mechanizmy boli testovaná v jednoduchej sieti s dvoma priamo prepojenými počítačmi, pričom jeden bol generátor paketov v rôznych frekvenciách a druhý bol zberač obmieňajúci spomínané mechanizmy. Prvá sada testov bola zameraná na efiktívnosť zberu paketov, pričom mal každý mechanizmus zozbierať čo najviac paketov za daný čas s meniacou sa frekvenciou generovania. Druhá sada bola zameraná na rýchlosť zozbierania variabilného počtu paketov s konštatnou frekvenciou generovania pre každú i\-te\-rá\-ciu. V prípade PF\_RING a netmapu boli testované ich špecifické libpcapové verzie. Výsledky ukázali, že netmap boli najefektívnejším mechanizmom, aj keď ostatné, okrem scapy, boli skoro rovnako efektívne. Výhodou netmapu bolo množstvo zahodených paketov, čo bolo výrazne malé hlavne s porovnaním štandarného libpcapu.\par
    Analýza zozbieraných dát spočíva vo výbere vhodného nástroja pre vi\-zua\-li\-zá\-ciu dát, úložisko a analýzu. Do úvahy boli brané databázové systémy typu \emph{SQL} a \emph{NoSQL}. SQL databáza paketov by mala buď veľa vzťahov medzi tabuľkami pre každý protokol alebo jednu velkú tabuľku všetkých protokolov a príslušných polí. NoSQL poskytuje vhodnejšiu formu dát, a to bez predvolenej štruktúry. Vhodná databáza by poskytovala aj možnosť vizualizovať dáta vo vhodnom nástroji. Taký nástroj, respektíve databázový systém je zoskupenie \emph{Elasticseach}u, \emph{Logstash}u a\emph{Kibany} (ELK koponenty) spolu s \emph{Filebeat} komponentom. ELK prestavuje rýchlo prehliadateľné úložisko - Elasticsearch a vizualizačný nástroj - Kibana.\par
    Návrh riešenia popisuje spôsob realizácie senzora spolu s úložiskom dát a ich následnej vizualizácie. Senzor je C++ program zachytávajúci sieťovú prevádzku pomocou libpcap knižnice vylepšenej netmapom, rozkladajúci pakety na rozpoznateľné protokoly a ich obohacovanie. Obohatené pakety sú zaielané v JSON formáte do Filebeat komponentu ELK. Prijaté dáta sú preposlané do Logstashu, kde sú rozložené z reťazcovej formy JSONu na JSON objekt a následné vložené do Elasticsearch databázy. Predpripravené vizualizácie v Kibane slúžia na špecifické zobrazenie dát a odpoveď na hlavné otázky zadania práce. Dodatočne je výsledný systém z veľkej väčšiny automatizovaný prostredníctvom nástroja \emph{Ansible} a funkčne sledovaný cez logové súbory cez \emph{rsyslog} server.\par
    Výsledný systém je funkčný zberač paketov s externe pripojeným da\-ta\-bá\-zo\-vým systémom ELK. Ako aj analýza opisuje, napriek potenciálne efektívnejším mechanizmom, bola zvolená knižnica libpcap namapovaná na natívne netmap API volania z dôvodu širokej kompatibility. Kompilácia senzora je možná s lubovoľnou verziou libpcap knižnice, ako aj v prípade nefunkčnosti netmapu na cieľovom zariadení štandarný libpcap. ELK komponenty poskytujú úložisko a zobrazovanie dát v reálnom čase, avšak vklad do databázy nie je rovnako rýchly ako potencionálna rýchlosť zberu sieťovej prevádzky. Ako dôsledok môže dochádzť k strate dát alebo oneskorenému zobrazeniu v Kibane. Vy\-lep\-še\-nie práce je možné práve v zrýchlení ukladaní paketov do databázy.\par
    Systém je celkovo správne zorganizovaný a zdokumentovaný spolu s ma\-nu\-ál\-nou inštalačnou príručnou s Ansible nasadením a príručkou pre po\-u\-ží\-va\-te\-ľa. V zmysle budúcej práce by mal byť senzor plne konfigurovateľný, a to vytiahnuť programom predefinované preferencie libpcap, širšie obohacovanie IP adries (ASN, mestá alebo konkrétne koordináty lokality), logovanie do vzdialeného syslog servera. V zmysle plného nasadenia senzor na zariadenie, chýba inštalácia spustiteľných súborov a senzora ako celok do operačného systému. Prípadne rozšíriť spúšťanie na \emph{systemd} službu, ktorá číta konfiguračný súbor z \emph{"/etc"} adresára.\par
    Na porovnanie s existujúcimi riešeniami, toto riešenie poskytuje vylepšenie v zobrazovaní dát, čo je jedna z najdôležitejších súčastí systému zabezpečúci monitorovanie siete z bezpečnostného hladiska. Aj v prípade menšieho zdr\-ža\-nia, zobrazenia sú cielené na správne časti zachytených paketov, ktorú môžu indikovať potenciálne hrozby alebo nezrovnalosti. Väčšina existujúcich riešení funguje ako jednotný systém s databázovým úložiskom, narozdiel od tohto riešenia s externým úložiskom. V prípade menších úprav vo Filebeat konfigurácii je možné nasadiť systém na viaceré zariadenie s distribuovanými zberačmi a centralizovanou databázou so zobrazovacím nástrojom.

\newpage
\bibliographystyle{plain}
\bibliography{sources}

\begin{appendices}
    \chapter{Installation guide} \label{appendix:install}
        \lstinputlisting[language=Clean, commentstyle=Clean, basicstyle=\tiny\ttfamily, breaklines=true]{guide/installation_guide}
    \chapter{User's guide} \label{appendix:userguide}
        \lstinputlisting[language=Clean, commentstyle=Clean, basicstyle=\tiny\ttfamily, breaklines=true]{guide/user_guide}
    \chapter{Script for testing automation} \label{appendix:script:testing}
        \lstinputlisting[language=bash, style=appendix, caption=Bash script for packet capture efficiency., label=listing:script:droprate]{src/script-droprate}
        \lstinputlisting[language=bash, style=appendix, caption=Bash script for elapsed time., label=listing:script:timed]{src/script-timed}
    \chapter{Linking various libpcap versions to one C source} \label{appendix:compilation:pcaps}
        \lstinputlisting[language=Clean, style=appendix, label=listing:compilation:pcaps]{src/compilation-proof}
    \chapter{Hping3 traffic generator} \label{appendix:hping3}
        \lstinputlisting[language=Clean, style=appendix, label=listing:hping3]{src/hping3_generator}
    \chapter{IIT.SRC research paper} \label{appendix:iitsrc:paper}
        \includepdf[pages=-]{src/iitsrc_paper}
    \chapter{Kibana dashboard} \label{appendix:sol:dashboard}
        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.38]{dashboard}
        \end{figure}
	\chapter{Configuration files}    
    	\section{Sensor configuration} \label{lst:sensor:config}
        	\lstinputlisting[language=bash, style=appendix, caption=Configuration example. File is located in \emph{project\_root}/resources/traffcol.yml.]{src/config}
    	\section{Logstash configuration} \label{lst:logstash:config}
        	\lstinputlisting[language=Clean, style=appendix, caption=Configuration file on machine with installed Logstash (/etc/logstash/conf.d/sensor.conf).]{src/logstash.conf}
    \chapter{Plan of work}
        \section{Winter semester}
            \lstinputlisting[language=Clean, style=appendix]{plan/december}    
        \section{Winter semester evaluation}
            Staring in the summer before the semester I met with my supervisor and discussed the vision of the project with main target aspects. The plan for the winter semester was to properly analyze the problem and design a solution with everything documented in this thesis. I made progress each week and kept my supervisor posted with current changes and further work. I analyzed the problem in depth and briefly designed the final system. Although, the design was not complete and the thesis lacked correct implementation sections. Altogether, the thesis was handed over with the finalized analysis of the problem and mostly finished design.
        \section{Summer semester}
            \lstinputlisting[language=Clean, style=appendix]{plan/may}
        \section{Summer semester evaluation}
            The plan for finalizing the system included full implementation and documentation. More or less, my progress was following the specified plan, but after a few week time, I diverged from the original plan and was falling back. Nevertheless, after fixing issues that slowed me down (programming misconceptions and barriers and most appropriate solutions), I came back on track and followed the plan. Main changes in the plan include logging component from custom class implementation to utilizing the syslog server, and the program is not multi-threaded but single. I managed to finish all sections in time and add deployment options as extra, which makes it a good evenly distributed plan of work.
        
    \chapter{Digital submission}
        \noindent AIS registration number: \myEvidenceNumber\\
        Contents of the digital submission (ZIP archive): BP\_prilohy\_digital\_TomasBellus.zip\\
        \lstinputlisting[language=Clean]{guide/structure}
\end{appendices}
\end{document}